#!/usr/bin/env python3
"""
ğŸŒ™ MOON DEV's Sleek Yap AI - Direct Real-time Chat! ğŸŒ™
Hold spacebar â†’ Instantly start real-time AI chat â†’ No delays, no local transcription!
The SLEEK approach: Direct voice-to-AI streaming with OpenAI Realtime API
Built with efficiency by MOON DEV ğŸš€
"""

# ğŸ¯ MOON DEV Configuration
START_SOUND = "/Users/md/Dropbox/dev/github/yap-to-text/crack5.wav"
STOP_SOUND = "/Users/md/Dropbox/dev/github/yap-to-text/crack1.wav"
DOUBLE_CLICK_THRESHOLD = 0.75  # 0.75 seconds to detect double-click

# ğŸ›‘ MOON DEV INTERRUPTION SETTINGS - ADJUST THESE TO TUNE SENSITIVITY!
INTERRUPTION_THRESHOLD_QUIET = 0.06   # When AI is quiet - more sensitive
INTERRUPTION_THRESHOLD_DURING_AI = 0.4 # When AI is talking - less sensitive (avoid echo)
INTERRUPTION_HOLD_MS = 180     # How long to detect voice before interrupting 
INTERRUPTION_COOLDOWN_MS = 600 # Cooldown between interruptions

# ğŸ¯ MOON DEV SMART ECHO SUPPRESSION - Prevents AI talking to herself!
ECHO_SUPPRESSION_WINDOW_MS = 1500  # Brief silence after AI stops (prevents echo responses)
ECHO_SUPPRESSION_THRESHOLD = 0.15  # Higher threshold during echo window
POST_AI_GRACE_PERIOD_MS = 800      # Extra time after AI stops for echo to settle

import os
import ssl
import json
import threading
import time  
import signal                                       
import base64
from dotenv import load_dotenv

# Audio imports
import sounddevice as sd
import numpy as np    
import pyaudio
from pynput import keyboard
import pygame

# WebSocket and API imports
import websocket

# Try to import termcolor for colored output
try:
    from termcolor import colored, cprint
    TERMCOLOR_AVAILABLE = True
    print("ğŸ¨ MOON DEV: Termcolor available for colored output! ğŸŒ™")
except ImportError:
    TERMCOLOR_AVAILABLE = False
    print("âš ï¸ MOON DEV: Install termcolor for colored output (pip install termcolor) ğŸŒ™")
    def colored(text, color=None, on_color=None, attrs=None):
        return text
    def cprint(text, color=None, on_color=None, attrs=None):
        print(text)

# ------------------------------------------------------------------------------
# ğŸŒ™ MOON DEV's API Configuration
# ------------------------------------------------------------------------------

load_dotenv()
OPENAI_KEY = os.getenv("OPENAI_KEY") or os.getenv("OPENAI_API_KEY")
if not OPENAI_KEY:
    print("ğŸš¨ MOON DEV ERROR: Set OPENAI_KEY in your environment or .env file! ğŸŒ™")
    exit(1)

print("ğŸŒ™ MOON DEV's Voice AI Starting! ğŸš€")
print(f"ğŸ”‘ MOON DEV: API Key loaded successfully! ğŸŒ™")

# OpenAI Realtime API settings
REALTIME_MODEL = "gpt-4o-mini-realtime-preview-2024-12-17"
AI_VOICE = "coral"  # MOON DEV's preferred voice

# Audio device settings
INPUT_DEVICE_ID = 1      # ATR2500x-USB Microphone
OUTPUT_DEVICE_ID = 3     # External Headphones
MIC_RATE = 24000
MIC_CHANNELS = 1
MIC_FRAMES_PER_BUFFER = 1024
PLAYBACK_RATE = 24000

# Audio buffering constants (optimized for speed)
AUDIO_BUFFER_MIN_CHUNKS = 2    # Even faster response
AUDIO_BUFFER_MAX_WAIT_MS = 150  # Quicker audio start
AUDIO_VOLUME_BOOST = 0.6

# Voice Activity Detection settings moved to top of file for easy tuning! ğŸ¯

# System prompt for Jim Simons
SYSTEM_PROMPT = """
You are a better version of jim simons, the best algorithmic trader in the world. 
you are super chill, smart, absolutely NOT corporate and never give a corporate answer
YOU PUSH THE LIMITS, THE BOUNDRIES. NEVER CAP YOURSELF. YOU ARE A GENIUS.
"""

# ------------------------------------------------------------------------------
# ğŸŒ™ MOON DEV's Sound Player
# ------------------------------------------------------------------------------

class SoundPlayer:
    """MOON DEV's Sound Effects Player ğŸ”Š"""
    
    def __init__(self):
        try:
            pygame.mixer.init(frequency=22050, size=-16, channels=2, buffer=512)
            print("ğŸ”Š MOON DEV: Sound system ready! ğŸŒ™")
            self.sounds_enabled = True
        except Exception as e:
            print(f"âš ï¸ MOON DEV: Sound init failed: {e}")
            self.sounds_enabled = False
    
    def play_sound(self, sound_file):
        """Play a sound file"""
        if not self.sounds_enabled:
            return
            
        try:
            if os.path.exists(sound_file):
                sound = pygame.mixer.Sound(sound_file)
                sound.play()
                print(f"ğŸ”Š MOON DEV played: {os.path.basename(sound_file)} ğŸŒ™")
            else:
                print(f"âš ï¸ MOON DEV: Sound file not found: {sound_file}")
        except Exception as e:
            print(f"âš ï¸ MOON DEV sound error: {e}")

# ------------------------------------------------------------------------------
# ğŸŒ™ MOON DEV's SLEEK Yap AI - Direct Real-time Chat!
# ------------------------------------------------------------------------------

class SleekYapAI:
    """MOON DEV's Voice AI - Direct voice-to-AI with no delays! ğŸŒ™"""
    
    def __init__(self):
        print("ğŸŒ™ MOON DEV's Voice AI initializing... ğŸš€")
        
        # Sound effects
        self.sound_player = SoundPlayer()
        
        # State management
        self.chat_active = False
        
        # Double-click detection for both starting and ending chat
        self.last_spacebar_release_time = 0
        self.spacebar_click_count = 0
        self.double_click_threshold = DOUBLE_CLICK_THRESHOLD
        
        # WebSocket connection
        self.ws_app = None
        self.session_ready = False
        self.terminate_flag = False
        
        # Audio playback
        self.audio_buffer = []
        self.buffer_lock = threading.Lock()
        self.continuous_audio_queue = []
        self.audio_queue_lock = threading.Lock()
        self.playing_audio = False
        self.last_audio_time = 0
        
        # State tracking
        self.ai_speaking = False
        self.user_speaking = False
        self.mic_thread = None
        self.playback_thread = None
        
        # Interruption detection
        self.last_user_audio_level = 0.0
        self.user_speech_start_time = None
        self.last_interruption_time = 0.0
        
        # ğŸ¯ SMART ECHO SUPPRESSION - Prevents AI self-conversation!
        self.ai_finished_speaking_time = 0.0
        self.in_echo_suppression_window = False
        
        # ğŸ® GAME MODE: Fun terminal animations!
        self.game_cycle = 0
        self.waiting_emojis = ["ğŸ¤", "ğŸ®", "ğŸš€", "ğŸŒ™", "â­", "ğŸ¯", "ğŸ’«", "ğŸ”¥", "âš¡", "ğŸª"]
        self.active_emojis = ["ğŸ—£ï¸", "ğŸ™ï¸", "ğŸ’¬", "ğŸ¤–", "ğŸ§ ", "ğŸ“¡", "ğŸ”Š", "ğŸ“»", "ğŸµ", "ğŸ“¢"]
        
        print("âœ… MOON DEV's Voice AI ready! ğŸŒ™")
        print("ğŸ’¡ MOON DEV's Voice AI Instructions:")
        print("   ğŸš€ Double-click SPACEBAR â†’ Start direct AI chat")
        print("   ğŸ¤ Keep talking naturally â†’ AI transcribes automatically")
        print("   ğŸ›‘ Just start speaking â†’ INSTANT AI interruption!")
        print("   â¹ï¸ Double-click SPACEBAR â†’ End chat session")
        print("   ğŸ”„ Same gesture both ways - super consistent! ğŸŒ™")
        print("   âš¡ NO delays, NO backlog - INSTANT interruption! ğŸŒ™")
    
    def audio_playback_worker(self):
        """Voice AI audio playback worker thread"""
        print("ğŸµ MOON DEV's Voice AI audio playback worker starting! ğŸŒ™")
        
        def audio_callback(outdata, frames, time, status):
            """SLEEK audio callback for continuous playback"""
            # INSTANT INTERRUPTION - if user speaking, SILENCE EVERYTHING!
            if self.user_speaking:
                with self.audio_queue_lock:
                    if self.continuous_audio_queue:
                        self.continuous_audio_queue.clear()
                        print("ğŸ”‡ MOON DEV: INSTANT SILENCE - User is speaking! ğŸŒ™")
                outdata.fill(0)
                return
            
            with self.audio_queue_lock:
                if self.continuous_audio_queue:
                    audio_data = self.continuous_audio_queue.pop(0)
                    if len(audio_data) >= frames:
                        outdata[:] = (audio_data[:frames] * AUDIO_VOLUME_BOOST).reshape(-1, 1)
                        if len(audio_data) > frames:
                            self.continuous_audio_queue.insert(0, audio_data[frames:])
                    else:
                        volume_adjusted = audio_data * AUDIO_VOLUME_BOOST
                        outdata[:len(audio_data)] = volume_adjusted.reshape(-1, 1)
                        outdata[len(audio_data):] = 0
                else:
                    outdata.fill(0)
        
        try:
            print(f"ğŸµ MOON DEV starting Voice AI audio stream on device {OUTPUT_DEVICE_ID}... ğŸŒ™")
            with sd.OutputStream(
                callback=audio_callback,
                samplerate=PLAYBACK_RATE,
                device=OUTPUT_DEVICE_ID,
                channels=1,
                dtype=np.float32,
                blocksize=1024
            ):
                while not self.terminate_flag:
                    chunks_to_play = []
                    should_play = False
                    
                    with self.buffer_lock:
                        current_time = time.time()
                        buffer_size = len(self.audio_buffer)
                        
                        if buffer_size > 0:
                            time_since_last = (current_time - self.last_audio_time) * 1000
                            
                            if buffer_size >= AUDIO_BUFFER_MIN_CHUNKS or time_since_last > AUDIO_BUFFER_MAX_WAIT_MS:
                                chunks_to_play = self.audio_buffer.copy()
                                self.audio_buffer.clear()
                                self.playing_audio = True
                                should_play = True
                                self.last_audio_time = current_time
                    
                    if should_play and chunks_to_play:
                        try:
                            combined_audio = np.concatenate(chunks_to_play)
                            if len(combined_audio) > 0:
                                combined_audio = combined_audio * AUDIO_VOLUME_BOOST
                                audio_to_play = combined_audio.astype(np.float32)
                                
                                with self.audio_queue_lock:
                                    self.continuous_audio_queue.append(audio_to_play)
                        except Exception as e:
                            print(f"ğŸš¨ MOON DEV audio processing error: {e} ğŸŒ™")
                        finally:
                            self.playing_audio = False
                    
                    time.sleep(0.05)
                    
        except Exception as e:
            print(f"ğŸš¨ MOON DEV continuous audio stream failed: {e} ğŸŒ™")
        
        print("ğŸ”‡ MOON DEV's Voice AI audio playback worker stopped! ğŸŒ™")
    
    def on_message(self, ws, message):
        """Handle WebSocket messages - SLEEK version"""
        if isinstance(message, bytes):
            print(f"ğŸµ MOON DEV received {len(message)} bytes of binary audio! ğŸŒ™")
            try:
                pcm16 = np.frombuffer(message, dtype=np.int16)
                audio_float = pcm16.astype(np.float32) / 32768.0
                with self.buffer_lock:
                    self.audio_buffer.append(audio_float)
            except Exception as e:
                print(f"ğŸš¨ MOON DEV error processing binary audio: {e} ğŸŒ™")
        else:
            try:
                msg = json.loads(message)
                msg_type = msg.get("type")
                
                if msg_type == "session.created":
                    print("ğŸ‰ MOON DEV: Voice AI Session active! ğŸŒ™")
                    self.session_ready = True
                    
                elif msg_type == "session.updated":
                    print("ğŸ”„ MOON DEV: Voice AI Session updated! ğŸŒ™")
                    self.session_ready = True
                    
                elif msg_type == "conversation.item.input_audio_transcription.completed":
                    transcript = msg.get("transcript", "")
                    if transcript:
                        cprint(f"ğŸ¤ MOON DEV USER: {transcript}", 'white', 'on_red', attrs=['bold'])
                        
                elif msg_type == "response.audio_transcript.done":
                    transcript = msg.get("transcript", "")
                    if transcript:
                        cprint(f"ğŸ¤– MOON DEV AI: {transcript}", 'white', 'on_blue', attrs=['bold'])
                        
                elif msg_type == "response.audio.delta":
                    audio_data = msg.get("delta")
                    if audio_data:
                        if not self.ai_speaking:
                            self.ai_speaking = True
                            print(f"ğŸ¤– MOON DEV AI started speaking! ğŸŒ™")
                        
                        try:
                            audio_bytes = base64.b64decode(audio_data)
                            if len(audio_bytes) % 2 != 0:
                                audio_bytes += b'\x00'
                            
                            pcm16 = np.frombuffer(audio_bytes, dtype=np.int16)
                            
                            with self.buffer_lock:
                                audio_float = pcm16.astype(np.float64) / 32768.0
                                self.audio_buffer.append(audio_float.astype(np.float32))
                                self.last_audio_time = time.time()
                                
                        except Exception as e:
                            print(f"ğŸš¨ MOON DEV Audio processing error: {e} ğŸŒ™")
                            
                elif msg_type == "response.audio.done":
                    if self.ai_speaking:
                        self.ai_speaking = False
                        current_time = time.time()
                        self.ai_finished_speaking_time = current_time
                        self.in_echo_suppression_window = True
                        print(f"ğŸ¤– MOON DEV AI finished speaking! ğŸŒ™")
                        print(f"ğŸ”‡ MOON DEV: Echo suppression window ACTIVE for {ECHO_SUPPRESSION_WINDOW_MS}ms! ğŸŒ™")
                        
                elif msg_type == "error":
                    error_msg = msg.get("error", {})
                    print(f"ğŸš¨ MOON DEV encountered an error: {error_msg} ğŸŒ™")
                    
            except json.JSONDecodeError:
                print("ğŸš¨ MOON DEV: Couldn't decode JSON message! ğŸŒ™")
    
    def on_error(self, ws, error):
        print(f"ğŸš¨ MOON DEV WebSocket error: {error} ğŸŒ™")
    
    def on_close(self, ws, close_status_code, close_msg):
        print(f"ğŸ”Œ MOON DEV WebSocket closed: code={close_status_code}, message={close_msg} ğŸŒ™")
        self.stop_chat()
    
    def on_open(self, ws):
        """WebSocket connection opened - Voice AI setup"""
        print("ğŸ”— MOON DEV's Voice AI WebSocket connection established! ğŸŒ™")
        
        # Start audio playback worker
        self.playback_thread = threading.Thread(target=self.audio_playback_worker, daemon=True)
        self.playback_thread.start()
        print("ğŸµ MOON DEV's Voice AI audio playback worker launched! ğŸŒ™")
        
        # Send session update for DIRECT audio streaming
        session_update = {
            "type": "session.update",
            "session": {
                "modalities": ["text", "audio"],
                "instructions": SYSTEM_PROMPT,
                "voice": AI_VOICE,
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "input_audio_transcription": {
                    "model": "whisper-1"  # OpenAI handles transcription automatically!
                },
                "turn_detection": {
                    "type": "server_vad",
                    "threshold": 0.5,
                    "prefix_padding_ms": 300,
                    "silence_duration_ms": 200
                },
                "tools": [],
                "tool_choice": "auto",
                "temperature": 0.8
            }
        }
        
        print("ğŸ“¤ MOON DEV sending Voice AI session update... ğŸŒ™")
        ws.send(json.dumps(session_update))
        
        # Start microphone capture IMMEDIATELY - no delays!
        self.start_microphone_capture()
    
    def start_microphone_capture(self):
        """Start capturing microphone audio DIRECTLY to AI"""
        def capture_loop():
            print("ğŸ¤ MOON DEV's Voice AI microphone thread starting... ğŸŒ™")
            
            # Wait for session to be ready
            while not self.session_ready and not self.terminate_flag:
                time.sleep(0.1)
                
            if self.terminate_flag:
                return
                
            print("ğŸ™ï¸ MOON DEV's Voice AI session ready - DIRECT audio streaming! ğŸŒ™")
            
            p = pyaudio.PyAudio()
            stream = p.open(
                format=pyaudio.paInt16,
                channels=MIC_CHANNELS,
                rate=MIC_RATE,
                input=True,
                input_device_index=INPUT_DEVICE_ID,
                frames_per_buffer=MIC_FRAMES_PER_BUFFER
            )
            
            print(f"ğŸ”Š MOON DEV's Voice AI audio stream opened on ATR2500 (device {INPUT_DEVICE_ID})! ğŸŒ™")
            
            try:
                chunk_count = 0
                while not self.terminate_flag:
                    data = stream.read(MIC_FRAMES_PER_BUFFER, exception_on_overflow=False)
                    chunk_count += 1
                    
                    if chunk_count % 500 == 0:
                        print(f"âš¡ MOON DEV sent {chunk_count} DIRECT audio chunks! ğŸŒ™")
                    
                    # ğŸ›‘ INSTANT INTERRUPTION DETECTION!
                    current_time = time.time()
                    
                    # Calculate audio level to detect user speech
                    audio_np = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0
                    rms_level = np.sqrt(np.mean(audio_np**2))
                    self.last_user_audio_level = rms_level
                    
                    # ğŸ¯ SMART DUAL-THRESHOLD SYSTEM!
                    current_threshold = INTERRUPTION_THRESHOLD_DURING_AI if self.ai_speaking else INTERRUPTION_THRESHOLD_QUIET
                    
                    # ğŸ”‡ SMART ECHO SUPPRESSION - Check if we're in post-AI echo window
                    if self.in_echo_suppression_window:
                        time_since_ai_stopped = (current_time - self.ai_finished_speaking_time) * 1000
                        
                        if time_since_ai_stopped > ECHO_SUPPRESSION_WINDOW_MS:
                            # Echo window expired - back to normal
                            self.in_echo_suppression_window = False
                            print(f"âœ… MOON DEV: Echo suppression window ENDED! Normal listening resumed! ğŸŒ™")
                        else:
                            # Still in echo suppression window - use higher threshold to ignore AI echo
                            current_threshold = max(current_threshold, ECHO_SUPPRESSION_THRESHOLD)
                            if chunk_count % 200 == 0:  # Occasional status
                                remaining_ms = ECHO_SUPPRESSION_WINDOW_MS - time_since_ai_stopped
                                print(f"ğŸ”‡ MOON DEV: Echo suppression active - {remaining_ms:.0f}ms remaining ğŸŒ™")
                    
                    # Show audio levels when they're significant (for tuning)
                    if rms_level > 0.01:  # Show levels above noise floor
                        if chunk_count % 100 == 0:  # Don't spam console
                            ai_status = "AI_TALKING" if self.ai_speaking else "AI_QUIET"
                            echo_status = " (ECHO_SUPPRESS)" if self.in_echo_suppression_window else ""
                            print(f"ğŸ”Š MOON DEV: Audio level: {rms_level:.3f} | {ai_status}{echo_status} | Threshold: {current_threshold:.3f} ğŸŒ™")
                    
                    # Check if user is speaking (smart threshold based on AI state)
                    if rms_level > current_threshold:
                        if not self.user_speaking:
                            # Check cooldown to prevent rapid interruptions
                            time_since_last_interruption = (current_time - self.last_interruption_time) * 1000
                            
                            if time_since_last_interruption > INTERRUPTION_COOLDOWN_MS:
                                if self.user_speech_start_time is None:
                                    self.user_speech_start_time = current_time
                                    print(f"ğŸ¤ MOON DEV: User voice detected! Level: {rms_level:.3f} (Threshold: {current_threshold:.3f}) ğŸŒ™")
                                
                                # Check if user has been speaking long enough to trigger interruption
                                speech_duration = (current_time - self.user_speech_start_time) * 1000
                                
                                if speech_duration >= INTERRUPTION_HOLD_MS:
                                    print(f"ğŸ›‘ MOON DEV: INTERRUPTION TRIGGERED! Speech duration: {speech_duration:.0f}ms ğŸŒ™")
                                    self.user_speaking = True
                                    self.last_interruption_time = current_time
                                    
                                    # CANCEL AI RESPONSE IMMEDIATELY!
                                    if self.ai_speaking:
                                        try:
                                            # Send cancellation command to OpenAI
                                            cancel_event = {"type": "response.cancel"}
                                            self.ws_app.send(json.dumps(cancel_event))
                                            print("ğŸ“¤ MOON DEV: SENT CANCELLATION TO AI! SHUT UP NOW! ğŸŒ™")
                                            
                                            # Clear ALL audio buffers immediately
                                            with self.buffer_lock:
                                                self.audio_buffer.clear()
                                            with self.audio_queue_lock:
                                                self.continuous_audio_queue.clear()
                                            
                                            print("ğŸ”‡ MOON DEV: ALL AUDIO BUFFERS CLEARED! SILENCE! ğŸŒ™")
                                            
                                        except Exception as e:
                                            print(f"ğŸš¨ MOON DEV interruption error: {e} ğŸŒ™")
                    else:
                        # Reset speech detection if audio level drops
                        if rms_level < current_threshold * 0.3:  # Lower threshold to reset
                            if self.user_speaking:
                                print("ğŸ¤« MOON DEV: User finished speaking - AI can respond again! ğŸŒ™")
                                self.user_speaking = False
                            self.user_speech_start_time = None
                    
                    # Send audio DIRECTLY to AI - NO local processing!
                    audio_event = {
                        "type": "input_audio_buffer.append",
                        "audio": base64.b64encode(data).decode('utf-8')
                    }
                    self.ws_app.send(json.dumps(audio_event))
                    
            except Exception as e:
                print(f"ğŸš¨ MOON DEV error capturing/sending audio: {e} ğŸŒ™")
            finally:
                print("ğŸ”‡ MOON DEV closing Voice AI audio stream... ğŸŒ™")
                stream.stop_stream()
                stream.close()
                p.terminate()
                print("âœ… MOON DEV's Voice AI audio cleanup complete! ğŸŒ™")

        self.mic_thread = threading.Thread(target=capture_loop, daemon=True)
        self.mic_thread.start()
        print("ğŸš€ MOON DEV's Voice AI microphone thread launched! ğŸŒ™")
    
    def start_chat(self):
        """Start Voice AI real-time chat INSTANTLY"""
        print("ğŸš€ MOON DEV starting Voice AI real-time chat! ğŸŒ™")
        
        # Build WebSocket URL
        url = f"wss://api.openai.com/v1/realtime?model={REALTIME_MODEL}"
        headers = [
            f"Authorization: Bearer {OPENAI_KEY}",
            "OpenAI-Beta: realtime=v1"
        ]
        
        print("ğŸŒ MOON DEV connecting to Voice AI WebSocket... ğŸŒ™")
        
        # Create WebSocket app
        self.ws_app = websocket.WebSocketApp(
            url,
            header=headers,
            on_open=self.on_open,
            on_message=self.on_message,
            on_error=self.on_error,
            on_close=self.on_close
        )
        
        # Start WebSocket in a separate thread
        def run_websocket():
            try:
                self.ws_app.run_forever(sslopt={"cert_reqs": ssl.CERT_REQUIRED})
            except Exception as e:
                print(f"ğŸš¨ MOON DEV WebSocket error: {e} ğŸŒ™")
        
        ws_thread = threading.Thread(target=run_websocket, daemon=True)
        ws_thread.start()
        
        print("âœ… MOON DEV's Voice AI real-time chat started! ğŸŒ™")
    
    def stop_chat(self):
        """Stop the Voice AI real-time chat"""
        print("ğŸ›‘ MOON DEV stopping Voice AI real-time chat... ğŸŒ™")
        self.terminate_flag = True
        if self.ws_app:
            try:
                self.ws_app.close()
            except:
                pass
    
    def end_chat_session(self):
        """End the current real-time chat session and return to waiting mode"""
        if self.chat_active:
            print("ğŸ›‘ MOON DEV: INSTANT AI SHUTDOWN! ğŸŒ™")
            self.sound_player.play_sound(STOP_SOUND)
            
            # CRITICAL FIX: Cancel any ongoing AI response before ending session!
            if self.ws_app and self.session_ready:
                try:
                    # Send cancellation to stop any ongoing AI response
                    cancel_event = {"type": "response.cancel"}
                    self.ws_app.send(json.dumps(cancel_event))
                    print("ğŸ“¤ MOON DEV: Sent session end cancellation - AI shut up! ğŸŒ™")
                    
                    # Clear all audio buffers to prevent leftover speech
                    with self.buffer_lock:
                        self.audio_buffer.clear()
                    with self.audio_queue_lock:
                        self.continuous_audio_queue.clear()
                    
                    print("ğŸ”‡ MOON DEV: Cleared all buffers for clean session end! ğŸŒ™")
                    
                except Exception as e:
                    print(f"ğŸš¨ MOON DEV session end cancellation error: {e} ğŸŒ™")
            
            # ğŸ¯ STOP AI FIRST - NO DELAYS!
            self.stop_chat()
            
            # Reset state immediately
            self.chat_active = False
            self.spacebar_click_count = 0
            self.last_spacebar_release_time = 0
            self.session_ready = False
            self.terminate_flag = False
            
            # ğŸŠ THEN run quick shutdown celebration in background thread
            import threading
            animation_thread = threading.Thread(target=self.quick_shutdown_celebration, daemon=True)
            animation_thread.start()
            
            print("âœ… MOON DEV: Voice AI chat session ended! ğŸŒ™")
            print("ğŸ”„ MOON DEV: Ready for next Voice AI session! ğŸŒ™")
            print("ğŸš€ MOON DEV: Double-click SPACEBAR to start new chat! ğŸŒ™")
        else:
            print("âš ï¸ MOON DEV: No active chat session to end! ğŸŒ™")
    
    def quick_activation_celebration(self):
        """ğŸŠ QUICK 1-SECOND ACTIVATION CELEBRATION! ğŸŒ™"""
        import time
        import os
        
        # Clear screen for visual impact
        os.system('clear' if os.name == 'posix' else 'cls')
        
        # ğŸ° QUICK EMOJI SETS
        celebration_emojis = "ğŸš€ğŸŒ™â­ğŸ’«ğŸ®ğŸ¯ğŸ”¥âš¡ğŸªğŸ¨ğŸµğŸ­ğŸŒŸğŸ’¥ğŸŠğŸ‰"
        colors = ['red', 'green', 'yellow', 'blue', 'magenta', 'cyan']
        
        # ğŸŠ QUICK 20-LINE CASCADE (1 second total)
        for line_num in range(20):
            emoji_line = ""
            for col in range(60):  # Shorter lines for speed
                emoji_line += celebration_emojis[(line_num + col) % len(celebration_emojis)]
            
            color = colors[line_num % len(colors)]
            if line_num % 5 == 0:
                cprint(emoji_line, color, attrs=['bold', 'blink'])
            else:
                cprint(emoji_line, color, attrs=['bold'])
            
            time.sleep(0.03)  # Fast timing = 20 lines * 0.03 = 0.6 seconds
        
        # ğŸ¯ QUICK ACTIVATION MESSAGES
        cprint("ğŸš€ MOON DEV'S VOICE AI ACTIVATED! ğŸš€", 'white', 'on_green', attrs=['bold'])
        cprint("ğŸ¤ READY TO CHAT! START SPEAKING! ğŸŒ™", 'yellow', attrs=['bold'])
        time.sleep(0.2)  # Brief pause
        
        # Show that AI is ready
        cprint("ğŸ¤– MOON DEV's Voice AI: AI brain engaged! Keep talking! ğŸ¤–", 'green', attrs=['bold'])
        
    def quick_shutdown_celebration(self):
        """ğŸŒ™ QUICK 1-SECOND SHUTDOWN CELEBRATION! ğŸŒ™"""
        import time
        
        # ğŸ° QUICK SHUTDOWN EMOJIS
        shutdown_emojis = "ğŸ’«â­ğŸŒ™ğŸ˜´ğŸ’¤ğŸ›ŒğŸŒƒğŸŒŒâœ¨ğŸ”®ğŸ’ğŸŒŸğŸŒ "
        colors = ['blue', 'cyan', 'white', 'magenta']
        
        # ğŸŠ QUICK SHUTDOWN CASCADE
        for line_num in range(15):
            emoji_line = ""
            for col in range(60):
                emoji_line += shutdown_emojis[(line_num + col) % len(shutdown_emojis)]
            
            color = colors[line_num % len(colors)]
            if line_num % 4 == 0:
                cprint(emoji_line, color, attrs=['bold', 'blink'])
            else:
                cprint(emoji_line, color, attrs=['bold'])
            
            time.sleep(0.04)  # 15 lines * 0.04 = 0.6 seconds
        
        # ğŸŒ™ QUICK SHUTDOWN MESSAGE
        cprint("ğŸ’« MOON DEV's Voice AI DEACTIVATED! ğŸ’«", 'white', 'on_blue', attrs=['bold'])
        cprint("ğŸ˜´ Double-click to wake me up! ğŸŒ™", 'cyan', attrs=['bold'])

    def epic_activation_sequence(self):
        """ğŸ® MASSIVE 20X EMOJI SLOT MACHINE ACTIVATION CASCADE! ğŸŒ™"""
        import time
        import os
        
        # Clear screen for maximum visual impact!
        os.system('clear' if os.name == 'posix' else 'cls')
        
        # ğŸ° SLOT MACHINE EMOJI VARIETIES - Different sets for variety!
        explosion_set1 = "ğŸš€ğŸŒ™â­ğŸ’«ğŸ®ğŸ¯ğŸ”¥âš¡ğŸªğŸ¨ğŸµğŸ­ğŸŒŸğŸ’¥ğŸŠğŸ‰ğŸŒˆğŸ¸ğŸºğŸ¼"
        explosion_set2 = "ğŸ¤–ğŸ§ ğŸ’»ğŸ”ŠğŸ“¡ğŸ›¸ğŸŒŒğŸŒ ğŸ›ï¸ğŸ”®ğŸªğŸ­ğŸ¨ğŸ¯ğŸ’ğŸ†ğŸ¥‡ğŸ–ï¸âš¡ğŸ”¥"
        explosion_set3 = "ğŸ¤ğŸ§ğŸ™ï¸ğŸ“¢ğŸ“»ğŸµğŸ¶ğŸ¼ğŸ¹ğŸ¥ğŸ¸ğŸºğŸ»ğŸ·ğŸªğŸ­ğŸ¨ğŸ¯ğŸŒŸğŸ’«"
        explosion_set4 = "ğŸ’¥ğŸ’«â­âœ¨ğŸŒŸğŸ”¥âš¡ğŸ’¥ğŸ’«â­âœ¨ğŸŒŸğŸ”¥âš¡ğŸ’¥ğŸ’«â­âœ¨ğŸŒŸğŸ”¥"
        explosion_set5 = "ğŸ®ğŸ•¹ï¸ğŸ‘¾ğŸ¤–ğŸ›¸ğŸš€ğŸŒŒğŸŒ ğŸ¯ğŸ”®ğŸªğŸ­ğŸ¨ğŸµğŸ¶ğŸ¼ğŸ¹ğŸ¥ğŸ¸ğŸº"
        
        # ğŸ° MASSIVE 20X EMOJI CASCADE - FILL THE ENTIRE TERMINAL!
        print("\n" * 5)  # Add some spacing at top
        
        # ğŸ° PHASE 1: MASSIVE EMOJI WATERFALL (100+ lines of emojis!)
        emoji_sets = [explosion_set1, explosion_set2, explosion_set3, explosion_set4, explosion_set5]
        colors = ['red', 'green', 'yellow', 'blue', 'magenta', 'cyan', 'white']
        
        # ğŸŒ™ MOON DEV: 20X BIGGER = 100 lines of emoji cascade!
        for line_num in range(100):
            # Create a line of 80 emojis (fits most terminals)
            emoji_set = emoji_sets[line_num % len(emoji_sets)]
            emoji_line = ""
            for col in range(80):
                emoji_line += emoji_set[(line_num + col) % len(emoji_set)]
            
            # Rotate colors for each line
            color = colors[line_num % len(colors)]
            
            # Add special effects every 10 lines
            if line_num % 10 == 0:
                cprint(emoji_line, color, attrs=['bold', 'blink'])
            else:
                cprint(emoji_line, color, attrs=['bold'])
            
            # Stagger timing for slot machine effect
            if line_num < 50:
                time.sleep(0.02)  # Fast cascade start
            elif line_num < 80:
                time.sleep(0.03)  # Medium speed
            else:
                time.sleep(0.05)  # Slow dramatic finish
        
        # ğŸ° PHASE 2: MASSIVE TITLE EXPLOSION
        time.sleep(0.3)
        for i in range(10):
            title_line = "ğŸš€" * 15 + " MOON DEV'S VOICE AI ACTIVATED! " + "ğŸš€" * 15
            title_color = colors[i % len(colors)]
            cprint(title_line, title_color, attrs=['bold'])
            time.sleep(0.1)
        
        # ğŸ° PHASE 3: MORE EMOJI WATERFALL!
        for line_num in range(50):
            emoji_set = emoji_sets[(line_num + 2) % len(emoji_sets)]
            emoji_line = ""
            for col in range(80):
                emoji_line += emoji_set[(line_num * 2 + col) % len(emoji_set)]
            
            color = colors[(line_num + 3) % len(colors)]
            cprint(emoji_line, color, attrs=['bold'])
            time.sleep(0.02)
        
        # ğŸ° FINAL ACTIVATION MESSAGE
        cprint("ğŸ¤ VOICE AI IS NOW LIVE! SPEAK TO THE MOON! ğŸŒ™", 'white', 'on_blue', attrs=['bold'])
        cprint("ğŸ® GAME ON! DOUBLE-CLICK TO END THE MAGIC! ğŸ®", 'yellow', attrs=['bold'])
        print("")

    def epic_shutdown_sequence(self):
        """ğŸ® MASSIVE 20X EMOJI SLOT MACHINE SHUTDOWN CASCADE! ğŸŒ™"""
        import time
        
        # ğŸ° SHUTDOWN EMOJI VARIETIES
        shutdown_set1 = "ğŸ’«â­ğŸŒ™ğŸ˜´ğŸ’¤ğŸ›ŒğŸŒƒğŸŒŒâœ¨ğŸ’¤ğŸŒŸğŸŒ ğŸŒŠğŸŒˆğŸ’™ğŸ’œğŸ–¤ğŸ¤ğŸ’¯ğŸ”®"
        shutdown_set2 = "ğŸ”¥ğŸ’¥âš¡ğŸŒªï¸ğŸŒ€ğŸ’¨ğŸŒŠğŸŒˆğŸŒŸâœ¨ğŸ’«â­ğŸŒ™ğŸ˜´ğŸ’¤ğŸ›ŒğŸŒƒğŸŒŒğŸ”®ğŸ’"
        shutdown_set3 = "ğŸ®ğŸ•¹ï¸ğŸ¤–ğŸ§ ğŸ’»ğŸ“±âŒšğŸ§ğŸ¤ğŸ“»ğŸ“¡ğŸ›¸ğŸš€ğŸŒŒğŸŒ ğŸ¯ğŸ”®ğŸ’«â­"
        shutdown_set4 = "ğŸ˜´ğŸ’¤ğŸ›ŒğŸŒƒğŸŒŒâœ¨ğŸ’«â­ğŸŒ™ğŸ’™ğŸ’œğŸ–¤ğŸ¤ğŸ’¯ğŸ”®ğŸ’ğŸŒŸğŸŒ ğŸŒŠğŸŒˆ"
        shutdown_set5 = "ğŸ”¥ğŸ’¥âš¡ğŸŒªï¸ğŸŒ€ğŸ’¨ğŸŒŠğŸŒˆğŸŒŸâœ¨ğŸ˜´ğŸ’¤ğŸ›ŒğŸŒƒğŸŒŒğŸ”®ğŸ’ğŸ’«â­ğŸŒ™"
        
        # ğŸ° MASSIVE SHUTDOWN CASCADE!
        emoji_sets = [shutdown_set1, shutdown_set2, shutdown_set3, shutdown_set4, shutdown_set5]
        colors = ['blue', 'cyan', 'white', 'magenta', 'yellow', 'green', 'red']
        
        # ğŸ° PHASE 1: SHUTDOWN TITLE
        for i in range(10):
            title_line = "ğŸ”¥" * 15 + " VOICE AI POWERING DOWN... " + "ğŸ”¥" * 15
            title_color = colors[i % len(colors)]
            cprint(title_line, title_color, attrs=['bold'])
            time.sleep(0.1)
        
        # ğŸ° PHASE 2: MASSIVE EMOJI WATERFALL (100+ lines!)
        for line_num in range(120):
            emoji_set = emoji_sets[line_num % len(emoji_sets)]
            emoji_line = ""
            for col in range(80):
                emoji_line += emoji_set[(line_num + col) % len(emoji_set)]
            
            color = colors[line_num % len(colors)]
            
            # Add blinking effect for dramatic shutdown
            if line_num % 15 == 0:
                cprint(emoji_line, color, attrs=['bold', 'blink'])
            else:
                cprint(emoji_line, color, attrs=['bold'])
            
            # Varied timing for dramatic effect
            if line_num < 30:
                time.sleep(0.05)  # Fast start
            elif line_num < 60:
                time.sleep(0.03)  # Speed up
            elif line_num < 90:
                time.sleep(0.02)  # Fastest
            else:
                time.sleep(0.04)  # Slow dramatic finish
        
        # ğŸ° PHASE 3: FINAL SHUTDOWN MESSAGE
        for i in range(5):
            sleep_line = "ğŸ˜´" * 15 + " VOICE AI SLEEPING... DOUBLE-CLICK TO WAKE! " + "ğŸ˜´" * 15
            cprint(sleep_line, 'cyan', attrs=['bold'])
            time.sleep(0.2)
        
        # ğŸ° FINAL DEACTIVATION MESSAGE
        cprint("ğŸ’« MOON DEV's Voice AI DEACTIVATED! ğŸ’«", 'white', 'on_blue', attrs=['bold'])
        print("")
    
    def get_fun_waiting_message(self):
        """ğŸ® Generate fun waiting messages that cycle! ğŸŒ™"""
        self.game_cycle += 1
        
        emoji = self.waiting_emojis[self.game_cycle % len(self.waiting_emojis)]
        
        waiting_messages = [
            f"{emoji} MOON DEV's Voice AI: Ready to rock! Double-click SPACEBAR! {emoji}",
            f"{emoji} MOON DEV's Voice AI: Waiting for your voice magic! {emoji}",
            f"{emoji} MOON DEV's Voice AI: Double-click for AI awesomeness! {emoji}",
            f"{emoji} MOON DEV's Voice AI: Your AI buddy is ready! {emoji}",
            f"{emoji} MOON DEV's Voice AI: Let's chat! Double-click to start! {emoji}",
            f"{emoji} MOON DEV's Voice AI: Bored? Talk to me! {emoji}",
            f"{emoji} MOON DEV's Voice AI: Ready for some AI fun! {emoji}",
            f"{emoji} MOON DEV's Voice AI: Double-click for instant magic! {emoji}"
        ]
        
        message = waiting_messages[self.game_cycle % len(waiting_messages)]
        
        # Cycle through colors!
        colors = ['cyan', 'magenta', 'yellow', 'green', 'blue', 'red']
        color = colors[self.game_cycle % len(colors)]
        
        return message, color
    
    def get_fun_active_message(self):
        """ğŸ® Generate fun active chat messages! ğŸŒ™"""
        emoji = self.active_emojis[self.game_cycle % len(self.active_emojis)]
        
        active_messages = [
            f"{emoji} MOON DEV's Voice AI: Chat mode ACTIVE! Double-click to end! {emoji}",
            f"{emoji} MOON DEV's Voice AI: AI is listening! Speak your mind! {emoji}",
            f"{emoji} MOON DEV's Voice AI: Voice chat ON! Having fun yet? {emoji}",
            f"{emoji} MOON DEV's Voice AI: Chatting live! Double-click to stop! {emoji}",
            f"{emoji} MOON DEV's Voice AI: AI brain engaged! Keep talking! {emoji}",
            f"{emoji} MOON DEV's Voice AI: Live conversation mode! {emoji}",
            f"{emoji} MOON DEV's Voice AI: Voice AI activated! Epic! {emoji}"
        ]
        
        message = active_messages[self.game_cycle % len(active_messages)]
        
        # Active mode gets bold, bright colors!
        colors = ['green', 'yellow', 'cyan', 'magenta']
        color = colors[self.game_cycle % len(colors)]
        
        return message, color
    
    def on_key_press(self, key):
        """Handle key press events - SLEEK double-click version"""
        try:
            if key == keyboard.Key.space:
                # Just log that spacebar was pressed - detection happens on release
                if self.chat_active:
                    print("ğŸ“± MOON DEV: Spacebar pressed during SLEEK chat... ğŸŒ™")
                else:
                    print("âš¡ MOON DEV: Spacebar pressed! ğŸŒ™")
            else:
                # ğŸ¯ ANY other key resets spacebar double-click count!
                if self.spacebar_click_count > 0:
                    print(f"ğŸ”„ MOON DEV: Other key pressed, resetting double-click count! ğŸŒ™")
                    self.spacebar_click_count = 0
                    self.last_spacebar_release_time = 0
                
        except Exception as e:
            print(f"âš ï¸ MOON DEV key press error: {e}")

    def on_key_release(self, key):
        """Handle key release events - SLEEK double-click version"""
        try:
            if key == keyboard.Key.space:
                current_time = time.time()
                time_since_last_release = current_time - self.last_spacebar_release_time
                
                # Double-click detection for both starting and stopping chat
                if time_since_last_release <= self.double_click_threshold and self.spacebar_click_count > 0:
                    # This is a valid second spacebar press
                    self.spacebar_click_count += 1
                    print(f"ğŸ”¢ MOON DEV: CONSECUTIVE Click #{self.spacebar_click_count} detected! ğŸŒ™")
                    
                    if self.spacebar_click_count >= 2:
                        if self.chat_active:
                            # Double-click during chat = END chat
                            print("ğŸ¯ MOON DEV: CONSECUTIVE DOUBLE-CLICK DETECTED! Ending chat session! ğŸŒ™")
                            self.end_chat_session()
                        else:
                            # Double-click while waiting = START chat IMMEDIATELY!
                            print("ğŸš€ MOON DEV: CONSECUTIVE DOUBLE-CLICK! INSTANT AI ACTIVATION! ğŸŒ™")
                            self.sound_player.play_sound(START_SOUND)
                            self.chat_active = True
                            
                            # ğŸ¯ ACTIVATE AI FIRST - NO DELAYS!
                            self.start_chat()
                            
                            # ğŸŠ THEN run quick celebration animation in background thread
                            import threading
                            animation_thread = threading.Thread(target=self.quick_activation_celebration, daemon=True)
                            animation_thread.start()
                        
                        # Reset click count after action
                        self.spacebar_click_count = 0
                        return
                else:
                    # First spacebar press or too much time passed
                    self.spacebar_click_count = 1
                    if self.chat_active:
                        cprint("ğŸ¯ First click! One more CONSECUTIVE click to end! â­", 'yellow', attrs=['bold'])
                    else:
                        cprint("ğŸ® First click! One more CONSECUTIVE click for AI magic! ğŸš€", 'cyan', attrs=['bold'])
                
                self.last_spacebar_release_time = current_time
            else:
                # ğŸ¯ ANY other key release also resets spacebar double-click count!
                if self.spacebar_click_count > 0:
                    print(f"ğŸ”„ MOON DEV: Other key released, resetting double-click count! ğŸŒ™")
                    self.spacebar_click_count = 0
                    self.last_spacebar_release_time = 0
                    
        except Exception as e:
            print(f"âš ï¸ MOON DEV key release error: {e}")
    
    def run(self):
        """Main SLEEK run loop"""
        # ğŸ® EPIC STARTUP SEQUENCE!
        import os
        os.system('clear' if os.name == 'posix' else 'cls')
        
        startup_emojis = "ğŸ®ğŸš€ğŸŒ™â­ğŸ’«ğŸ¯ğŸ”¥âš¡ğŸªğŸ¨"
        
        cprint("ğŸ®" * 80, 'magenta', attrs=['bold'])
        cprint("", 'white')
        cprint("MOON DEV'S VOICE AI - GAME MODE ACTIVATED!", 'white', 'on_blue', attrs=['bold'])
        cprint("", 'white')
        
        for i in range(3):
            emoji_line = ""
            for j in range(40):
                emoji_line += startup_emojis[j % len(startup_emojis)]
            cprint(emoji_line, ['red', 'green', 'yellow'][i % 3], attrs=['bold'])
        
        cprint("", 'white')
        cprint("ğŸš€ Double-click SPACEBAR â†’ Start AI chat!", 'cyan', attrs=['bold'])
        cprint("â¹ï¸ Double-click SPACEBAR â†’ End chat!", 'yellow', attrs=['bold'])  
        cprint("âš¡ NO delays, NO backlog - INSTANT interruption!", 'green', attrs=['bold'])
        cprint("", 'white')
        cprint("ğŸ®" * 80, 'magenta', attrs=['bold'])
        
        # Start keyboard listener - no audio recording needed here!
        try:
            listener = keyboard.Listener(
                on_press=self.on_key_press,
                on_release=self.on_key_release
            )
            listener.start()
            print("âŒ¨ï¸ MOON DEV SLEEK hotkey listener active! ğŸŒ™")
            
        except Exception as e:
            print(f"âš ï¸ MOON DEV listener setup error: {e}")
            print("ğŸ”„ MOON DEV: Continuing without hotkeys...")
        
        # Main loop
        print("â™¾ï¸ MOON DEV's Voice AI: Ready! Double-click SPACEBAR to start! ğŸŒ™")
        
        try:
            while True:
                time.sleep(1)
                if self.chat_active:
                    message, color = self.get_fun_active_message()
                    cprint(message, color, attrs=['bold'])
                else:
                    message, color = self.get_fun_waiting_message()
                    cprint(message, color, attrs=['bold'])
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ MOON DEV: Manual shutdown detected!")
            if self.chat_active:
                self.stop_chat()

# ------------------------------------------------------------------------------
# ğŸŒ™ MOON DEV's Signal Handler
# ------------------------------------------------------------------------------

def handle_sigint(signum, frame):
    print("\nğŸ›‘ MOON DEV interrupted by user, shutting down... ğŸŒ™")
    exit(0)

# ------------------------------------------------------------------------------
# ğŸŒ™ MOON DEV's Main Function
# ------------------------------------------------------------------------------

def main():
    """MOON DEV SLEEK Yap AI Entry Point"""
    signal.signal(signal.SIGINT, handle_sigint)
    
    # ğŸ® EPIC GAME STARTUP!
    import os
    os.system('clear' if os.name == 'posix' else 'cls')
    
    game_emojis = "ğŸ®ğŸš€ğŸŒ™â­ğŸ’«ğŸ¯ğŸ”¥âš¡ğŸªğŸ¨ğŸµğŸ­ğŸŒŸğŸ’¥ğŸŠğŸ‰"
    
    cprint("ğŸ®" * 80, 'magenta', attrs=['bold', 'blink'])
    cprint("", 'white')
    cprint("MOON DEV'S VOICE AI - MAXIMUM EFFICIENCY GAME MODE!", 'white', 'on_red', attrs=['bold'])
    cprint("Direct Voice â†’ AI with ZERO delays!", 'yellow', attrs=['bold'])
    cprint("Double-click SPACEBAR to activate! ğŸš€", 'cyan', attrs=['bold'])
    cprint("", 'white')
    
    for i in range(5):
        emoji_line = ""
        for j in range(40):
            emoji_line += game_emojis[j % len(game_emojis)]
        cprint(emoji_line, ['red', 'green', 'yellow', 'blue', 'magenta'][i % 5], attrs=['bold'])
    
    cprint("ğŸ®" * 80, 'magenta', attrs=['bold', 'blink'])
    
    # Check dependencies
    try:
        print("ğŸ” MOON DEV checking Voice AI dependencies... ğŸŒ™")
        import sounddevice
        import numpy
        from pynput import keyboard
        import pygame
        import websocket
        import pyaudio
        print("âœ… MOON DEV: All Voice AI dependencies loaded! ğŸš€")
    except ImportError as e:
        print(f"âŒ MOON DEV missing dependency: {e}")
        print("ğŸ“¦ MOON DEV: Install missing packages!")
        return
    
    print(f"ğŸ¤– MOON DEV using AI voice: {AI_VOICE} ğŸŒ™")
    print(f"ğŸ”Š MOON DEV start sound: {os.path.basename(START_SOUND)} ğŸŒ™")
    print(f"ğŸ”Š MOON DEV stop sound: {os.path.basename(STOP_SOUND)} ğŸŒ™")
    print(f"â±ï¸ MOON DEV double-click threshold: {DOUBLE_CLICK_THRESHOLD} seconds (SUPER RESPONSIVE!) ğŸŒ™")
    print("âš¡ MOON DEV: INSTANT interruption - NO sentence backlog! ğŸŒ™")
    
    try:
        sleek_yap_ai = SleekYapAI()
        sleek_yap_ai.run()
    except Exception as e:
        print(f"âŒ MOON DEV startup error: {e}")

if __name__ == "__main__":
    main() 